{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T21:54:52.504560Z",
     "start_time": "2025-02-27T21:54:52.290096Z"
    }
   },
   "source": [
    "import stores\n",
    "import numpy as np\n",
    "from pympler import asizeof \n",
    "\n",
    "from performance_helper import performance_gen, performance_gen_leveled"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:16:54.340505Z",
     "start_time": "2025-02-27T21:07:34.146639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('tsne_transform/real_Data/GASscikit.npy', 'rb') as f:\n",
    "     embedding = np.load(f)\n",
    "     df = np.load(f)\n",
    "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=400, gran_ris=2, leveled_gen=True, leveldParams=[100, 10])"
   ],
   "id": "d900d0e2cc2b95c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  275.5070631504059\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  267.8834960460663\n",
      "All tasks completed\n",
      "Time to create stores:  16.320179224014282\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  284.23055052757263\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:16:55.035523Z",
     "start_time": "2025-02-27T21:16:54.438681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "678e8bf49fa07fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  607.0603427218579\n",
      "Max:  1289\n",
      "Min:  8\n",
      "Size of cloud storage 4176500592\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  606.193776112952\n",
      "Max:  979\n",
      "Min:  106\n",
      "Size of leveled cloud storage 338623656\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:18:57.604797Z",
     "start_time": "2025-02-27T21:16:55.044416Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "303d3b3a630b4778",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:18:57.696605Z",
     "start_time": "2025-02-27T21:18:57.689165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "b97718c8bef16a9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "42980384 42980.384 42980384\n",
      "42980.384 42980.384 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 77864 7320 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "31005.0 1.1629706655668601 1000\n",
      "31.005 1.1629706655668606 1000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:21:04.060190Z",
     "start_time": "2025-02-27T21:18:57.913007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "78aff7026414e726",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:21:04.201509Z",
     "start_time": "2025-02-27T21:21:04.195081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "af5d49916bd8972c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "42980384 42980.384 42980384\n",
      "42980.384 42980.384 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 77864 7320 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "28546.0 1.244028557755686 1000\n",
      "28.546 1.2440285577556849 1000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:21:04.252218Z",
     "start_time": "2025-02-27T21:21:04.250048Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8e740bed9e814606",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:21:04.340522Z",
     "start_time": "2025-02-27T21:21:04.339137Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9a21027499b32910",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:11:17.308026Z",
     "start_time": "2025-02-27T21:54:59.804078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('tsne_transform/real_Data/GASscikit.npy', 'rb') as f:\n",
    "     embedding = np.load(f)\n",
    "     df = np.load(f)\n",
    "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=400, gran_ris=4, leveled_gen=True, leveldParams=[100, 10])"
   ],
   "id": "698981ee089b12c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  697.8773050308228\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  258.4967110157013\n",
      "All tasks completed\n",
      "Time to create stores:  18.747118711471558\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  277.26540446281433\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:11:19.325125Z",
     "start_time": "2025-02-27T22:11:17.496094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "51ff8b5f0d8a42f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  2379.82532271096\n",
      "Max:  4463\n",
      "Min:  119\n",
      "Size of cloud storage 16254715360\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  605.1318507890961\n",
      "Max:  995\n",
      "Min:  106\n",
      "Size of leveled cloud storage 339445088\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:13:21.048707Z",
     "start_time": "2025-02-27T22:11:19.337321Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "f917fb7b906400d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:13:21.139938Z",
     "start_time": "2025-02-27T22:13:21.132209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "c67ef15ff51a1dd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "162330768 162330.768 162330768\n",
      "162330.768 162330.768 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 271976 42456 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "34816.0 1.1247300272166463 1000\n",
      "34.816 1.124730027216647 1000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:15:21.880550Z",
     "start_time": "2025-02-27T22:13:21.223252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "14d90c3206ca7136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:15:21.968384Z",
     "start_time": "2025-02-27T22:15:21.961011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "abc0415e651efb3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "162330768 162330.768 162330768\n",
      "162330.768 162330.768 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 271976 42456 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "33195.0 1.1711091053487581 1000\n",
      "33.195 1.171109105348758 1000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:15:22.067415Z",
     "start_time": "2025-02-27T22:15:22.065328Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e43236b6113550ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:15:22.148720Z",
     "start_time": "2025-02-27T22:15:22.146549Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cbddb582cdd12073",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:17:51.501009Z",
     "start_time": "2025-02-27T22:15:22.234943Z"
    }
   },
   "cell_type": "code",
   "source": "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=200, gran_ris=2, leveled_gen=True, leveldParams=[100, 10])",
   "id": "1835458e63e7c956",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  81.34415650367737\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  56.010499715805054\n",
      "All tasks completed\n",
      "Time to create stores:  8.772489309310913\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  64.80666637420654\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:17:51.723247Z",
     "start_time": "2025-02-27T22:17:51.536869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "68de3d803f941d8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  578.561416516612\n",
      "Max:  1289\n",
      "Min:  1\n",
      "Size of cloud storage 1059575040\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  266.8022429316064\n",
      "Max:  449\n",
      "Min:  37\n",
      "Size of leveled cloud storage 136995096\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:19:49.059279Z",
     "start_time": "2025-02-27T22:17:51.753655Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "71f472745260d727",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:19:49.110068Z",
     "start_time": "2025-02-27T22:19:49.103829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "42022e8393902dbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "40927232 40927.232 40927232\n",
      "41085.140562249 41085.140562249 996\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 70248 3672 996\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "25705.0 1.2812877416366566 996\n",
      "25.77409638554217 1.2751961018205824 996\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:21:47.125425Z",
     "start_time": "2025-02-27T22:19:49.158076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "2cc50dfd9cd8dd69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gagan/tsne/SecureANN/.venv/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/gagan/tsne/SecureANN/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:21:47.176481Z",
     "start_time": "2025-02-27T22:21:47.169608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "907f98ad7318ce89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "40927232 40927.232 40927232\n",
      "40938.1664994985 40938.1664994985 997\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 70248 472 997\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "24013.0 nan 997\n",
      "24.059177532597793 1.321170476583354 997\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:21:47.289405Z",
     "start_time": "2025-02-27T22:21:47.286388Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5d7cf50f2995685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:21:47.374483Z",
     "start_time": "2025-02-27T22:21:47.372448Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7e361aa4626a197a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:26:07.234712Z",
     "start_time": "2025-02-27T22:21:47.416154Z"
    }
   },
   "cell_type": "code",
   "source": "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=200, gran_ris=4, leveled_gen=True, leveldParams=[100, 10])",
   "id": "2023eee3ec914d9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  194.76128363609314\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  55.88121461868286\n",
      "All tasks completed\n",
      "Time to create stores:  9.022039413452148\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  64.92077851295471\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:26:07.476048Z",
     "start_time": "2025-02-27T22:26:07.281371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "e569103da7faca20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  2301.28242064753\n",
      "Max:  4388\n",
      "Min:  119\n",
      "Size of cloud storage 4182724336\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  269.2969515084505\n",
      "Max:  455\n",
      "Min:  43\n",
      "Size of leveled cloud storage 138258616\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:28:08.137304Z",
     "start_time": "2025-02-27T22:26:07.507480Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "dcabaad1aa1108a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:28:08.284636Z",
     "start_time": "2025-02-27T22:28:08.276334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "7c2b717de16f1a57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "158496944 158496.944 158496944\n",
      "158496.944 158496.944 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 276008 18968 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "31129.0 1.1976937582490195 1000\n",
      "31.129 1.1976937582490197 1000\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:30:07.119650Z",
     "start_time": "2025-02-27T22:28:08.377734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "e568c07ec357574f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T22:30:07.161754Z",
     "start_time": "2025-02-27T22:30:07.155861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "a8d8c092ed472df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "158496944 158496.944 158496944\n",
      "158496.944 158496.944 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 276008 18968 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "29793.0 1.242928788213065 1000\n",
      "29.793 1.2429287882130664 1000\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10e1f1b85440925"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
