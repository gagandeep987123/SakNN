{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T20:01:35.950400Z",
     "start_time": "2025-02-27T20:01:35.781571Z"
    }
   },
   "source": [
    "import stores\n",
    "import numpy as np\n",
    "from pympler import asizeof \n",
    "\n",
    "from performance_helper import performance_gen, performance_gen_leveled"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:10:53.294037Z",
     "start_time": "2025-02-27T20:02:22.861487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('tsne_transform/transformation_data/random_3d_scikit.npy', 'rb') as f:\n",
    "     embedding = np.load(f)\n",
    "     df = np.load(f)\n",
    "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=400, gran_ris=2, leveled_gen=True, leveldParams=[100, 10])"
   ],
   "id": "d900d0e2cc2b95c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  232.27476572990417\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  263.74406266212463\n",
      "All tasks completed\n",
      "Time to create stores:  14.047250270843506\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  277.81553530693054\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:10:54.027463Z",
     "start_time": "2025-02-27T20:10:53.299215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "678e8bf49fa07fae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  426.57566783564965\n",
      "Max:  834\n",
      "Min:  28\n",
      "Size of cloud storage 1226823328\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  522.0901032019053\n",
      "Max:  836\n",
      "Min:  140\n",
      "Size of leveled cloud storage 160007672\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:12:01.566735Z",
     "start_time": "2025-02-27T20:10:54.111694Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "303d3b3a630b4778",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:12:01.659934Z",
     "start_time": "2025-02-27T20:12:01.652339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "b97718c8bef16a9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "11269920 11269.92 11269920\n",
      "11269.92 11269.92 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 18120 3864 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "40781.0 1.103539608862073 1000\n",
      "40.781 1.1035396088620728 1000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:13:10.346038Z",
     "start_time": "2025-02-27T20:12:01.745355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "78aff7026414e726",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:13:10.448347Z",
     "start_time": "2025-02-27T20:13:10.442080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "af5d49916bd8972c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "11269920 11269.92 11269920\n",
      "11269.92 11269.92 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 18120 3864 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "37276.0 1.1763877877679265 1000\n",
      "37.276 1.1763877877679259 1000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:13:10.538916Z",
     "start_time": "2025-02-27T20:13:10.537020Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8e740bed9e814606",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:13:10.628977Z",
     "start_time": "2025-02-27T20:13:10.627584Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9a21027499b32910",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:27:35.334848Z",
     "start_time": "2025-02-27T20:13:10.709213Z"
    }
   },
   "cell_type": "code",
   "source": "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=400, gran_ris=4, leveled_gen=True, leveldParams=[100, 10])",
   "id": "698981ee089b12c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  580.4354598522186\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  266.55386996269226\n",
      "All tasks completed\n",
      "Time to create stores:  17.04847288131714\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  283.63031792640686\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:27:36.174544Z",
     "start_time": "2025-02-27T20:27:35.435781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "51ff8b5f0d8a42f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  1682.5543490496602\n",
      "Max:  2837\n",
      "Min:  220\n",
      "Size of cloud storage 4707943344\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  522.0005279831046\n",
      "Max:  822\n",
      "Min:  142\n",
      "Size of leveled cloud storage 160360896\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:28:44.358639Z",
     "start_time": "2025-02-27T20:27:36.259403Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "f917fb7b906400d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:28:44.455385Z",
     "start_time": "2025-02-27T20:28:44.445042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "c67ef15ff51a1dd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "43069056 43069.056 43069056\n",
      "43069.056 43069.056 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 64680 15768 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "42789.0 1.0798945039210561 1000\n",
      "42.789 1.0798945039210555 1000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:29:51.769501Z",
     "start_time": "2025-02-27T20:28:44.552633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "14d90c3206ca7136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:29:51.861724Z",
     "start_time": "2025-02-27T20:29:51.855359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "abc0415e651efb3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "43069056 43069.056 43069056\n",
      "43069.056 43069.056 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 64680 15768 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "41587.0 1.1134941164209047 1000\n",
      "41.587 1.1134941164209033 1000\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:29:51.955225Z",
     "start_time": "2025-02-27T20:29:51.953777Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e43236b6113550ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:29:52.134248Z",
     "start_time": "2025-02-27T20:29:52.132950Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cbddb582cdd12073",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:32:30.768617Z",
     "start_time": "2025-02-27T20:29:52.140429Z"
    }
   },
   "cell_type": "code",
   "source": "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=200, gran_ris=2, leveled_gen=True, leveldParams=[100, 10])",
   "id": "1835458e63e7c956",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  88.27859854698181\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  60.07335352897644\n",
      "All tasks completed\n",
      "Time to create stores:  9.883057355880737\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  69.98319268226624\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:32:31.018568Z",
     "start_time": "2025-02-27T20:32:30.815074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "68de3d803f941d8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  415.4275168681943\n",
      "Max:  827\n",
      "Min:  1\n",
      "Size of cloud storage 309980464\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  227.79423551171394\n",
      "Max:  350\n",
      "Min:  70\n",
      "Size of leveled cloud storage 61021192\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:33:37.999527Z",
     "start_time": "2025-02-27T20:32:31.055751Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "71f472745260d727",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:33:38.084842Z",
     "start_time": "2025-02-27T20:33:38.076768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "42022e8393902dbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "10987376 10987.376 10987376\n",
      "11007.2625250501 11007.2625250501 998\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "119984 119.984 119984 120 104\n",
      "119.98396793587175 119.98396793587175 20072 1688 998\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "35553.0 1.2194558695960314 998\n",
      "35.611222444889776 1.2168868501142864 998\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:34:46.528174Z",
     "start_time": "2025-02-27T20:33:38.194700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "2cc50dfd9cd8dd69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:34:46.623760Z",
     "start_time": "2025-02-27T20:34:46.613654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "907f98ad7318ce89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "10987376 10987.376 10987376\n",
      "10975.414242728184 10975.414242728184 997\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "119984 119.984 119984 120 104\n",
      "119.9839518555667 119.9839518555667 20072 1064 997\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "35715.0 1.230878919113264 997\n",
      "35.75025075225677 1.2293088221836894 997\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:34:46.778718Z",
     "start_time": "2025-02-27T20:34:46.776361Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5d7cf50f2995685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:34:46.795465Z",
     "start_time": "2025-02-27T20:34:46.793515Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7e361aa4626a197a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:38:55.661828Z",
     "start_time": "2025-02-27T20:34:46.840912Z"
    }
   },
   "cell_type": "code",
   "source": "result_store, result_store_enc, query_store, leveled_stores = stores.stores_gen_parallel(org_data=df, tsne_red=embedding, div_qrs=200, gran_ris=4, leveled_gen=True, leveldParams=[100, 10])",
   "id": "2023eee3ec914d9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tasks completed\n",
      "Time to create stores:  177.43776178359985\n",
      "Tsne processing\n",
      "Tsne processing Done\n",
      "Tsne processing time:  61.05098104476929\n",
      "All tasks completed\n",
      "Time to create stores:  10.133068323135376\n",
      "Result Store level1 Done\n",
      "Time to create leveled stores:  71.20049238204956\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:38:55.915565Z",
     "start_time": "2025-02-27T20:38:55.707688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"#Stats about result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in result_store:\n",
    "    store_lens.append(result_store[s].shape[0])\n",
    "    max_size = max(max_size, result_store[s].shape[0])\n",
    "    min_size = min(min_size, result_store[s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of cloud storage\",asizeof.asizeof(result_store_enc))\n",
    "\n",
    "print(\"\\n\\n#Stats about leveled result stores\")\n",
    "store_lens = []\n",
    "max_size = 1\n",
    "min_size = 1000000000\n",
    "for s in leveled_stores[0]:\n",
    "    store_lens.append(leveled_stores[0][s].shape[0])\n",
    "    max_size = max(max_size, leveled_stores[0][s].shape[0])\n",
    "    min_size = min(min_size, leveled_stores[0][s].shape[0])\n",
    "# print(sum(store_lens))\n",
    "# print(len(store_lens))\n",
    "print(\"Avg result store entry size: \",sum(store_lens)/len(store_lens))\n",
    "print(\"Max: \", max_size)\n",
    "print(\"Min: \", min_size)\n",
    "print(\"Size of leveled cloud storage\",asizeof.asizeof(leveled_stores[0]))"
   ],
   "id": "e569103da7faca20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Stats about result stores\n",
      "Avg result store entry size:  1655.0998730710135\n",
      "Max:  2837\n",
      "Min:  130\n",
      "Size of cloud storage 1200697984\n",
      "\n",
      "\n",
      "#Stats about leveled result stores\n",
      "Avg result store entry size:  228.42437749769442\n",
      "Max:  362\n",
      "Min:  78\n",
      "Size of leveled cloud storage 61353656\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:40:03.726747Z",
     "start_time": "2025-02-27T20:38:55.958880Z"
    }
   },
   "cell_type": "code",
   "source": "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40, result_sizes, query_sizes = performance_gen(df, query_store, result_store, result_store_enc, isEnc=True)",
   "id": "dcabaad1aa1108a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:40:03.812038Z",
     "start_time": "2025-02-27T20:40:03.803524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "7c2b717de16f1a57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "42513584 42513.584 42513584\n",
      "42513.584 42513.584 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 65336 11240 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "39771.0 1.1648476068147866 1000\n",
      "39.771 1.1648476068147866 1000\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:41:11.638146Z",
     "start_time": "2025-02-27T20:40:03.924990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oars50, recalls50, flags, recalls5, recalls10, recalls20, recalls30, recalls40, oars5, oars10, oars20, oars30, oars40,query_sizes1, query_sizes2, result_sizes1, result_sizes2  = (\n",
    "    performance_gen_leveled(\n",
    "        df, result_store, result_store_enc,\n",
    "        query_store_level1=leveled_stores[2],\n",
    "        result_store_level1=leveled_stores[0],\n",
    "        result_store_level1_enc=leveled_stores[1],\n",
    "        isEnc=True\n",
    "    )\n",
    ")"
   ],
   "id": "e568c07ec357574f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Tasks done\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T20:41:11.743574Z",
     "start_time": "2025-02-27T20:41:11.732612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"###Printing for result sizes###\")\n",
    "print(sum(result_sizes), np.average(result_sizes), np.sum(result_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(result_sizes[i] for i in indices) / len(indices), sum(result_sizes[i] for i in indices) / len(indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for result sizes###\")\n",
    "print(sum(query_sizes), np.average(query_sizes), np.sum(query_sizes),max(query_sizes),min(query_sizes))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(query_sizes[i] for i in indices) / len(indices), sum(query_sizes[i] for i in indices) / len(indices), max(result_sizes[i] for i in indices),min(result_sizes[i] for i in indices) ,len(indices))\n",
    "\n",
    "print(\"\\n\\n###Printing for 50###\")\n",
    "print(sum(recalls50), np.average(oars50), np.sum(flags))\n",
    "indices = np.where(np.array(flags) == True)[0]\n",
    "print(sum(recalls50[i] for i in indices) / len(indices), sum(oars50[i] for i in indices) / len(indices), len(indices))"
   ],
   "id": "a8d8c092ed472df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Printing for result sizes###\n",
      "42513584 42513.584 42513584\n",
      "42513.584 42513.584 1000\n",
      "\n",
      "\n",
      "###Printing for result sizes###\n",
      "120000 120.0 120000 120 120\n",
      "120.0 120.0 65336 11240 1000\n",
      "\n",
      "\n",
      "###Printing for 50###\n",
      "39736.0 1.1660646532832342 1000\n",
      "39.736 1.166064653283234 1000\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10e1f1b85440925"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
